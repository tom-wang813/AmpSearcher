{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from amp.data.diffusion.schedules import LinearSchedule, CosineSchedule, QuadraticSchedule\n",
    "from amp.data.diffusion.forward import DiffusionForward, DiscreteDataDiffusion\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61dcb16",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "source": [
    "## 测试连续数据的扩散过程\n",
    "\n",
    "我们将使用一个简单的2D高斯分布数据来测试连续数据的扩散过程。我们会：\n",
    "1. 生成初始数据\n",
    "2. 应用不同的noise schedule\n",
    "3. 观察不同时间步的扩散效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e04f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaussian_mixture(n_samples=1000):\n",
    "    mean1 = torch.tensor([2.0, 2.0])\n",
    "    mean2 = torch.tensor([-2.0, -2.0])\n",
    "    std = 0.5\n",
    "    \n",
    "    samples1 = torch.randn(n_samples // 2, 2) * std + mean1\n",
    "    samples2 = torch.randn(n_samples // 2, 2) * std + mean2\n",
    "    return torch.cat([samples1, samples2], dim=0)\n",
    "\n",
    "# 创建数据和时间步\n",
    "x_0 = create_gaussian_mixture()\n",
    "timesteps = [0, 100, 500, 999]  # 不同的时间步\n",
    "\n",
    "# 创建不同的schedule\n",
    "num_timesteps = 1000\n",
    "schedules = {\n",
    "    'Linear': LinearSchedule(num_timesteps),\n",
    "    'Cosine': CosineSchedule(num_timesteps),\n",
    "    'Quadratic': QuadraticSchedule(num_timesteps)\n",
    "}\n",
    "\n",
    "# 可视化不同schedule下的扩散过程\n",
    "fig, axes = plt.subplots(len(schedules), len(timesteps), figsize=(16, 12))\n",
    "\n",
    "for i, (schedule_name, schedule) in enumerate(schedules.items()):\n",
    "    diffusion = DiffusionForward(schedule)\n",
    "    \n",
    "    for j, t in enumerate(timesteps):\n",
    "        t_tensor = torch.ones(x_0.shape[0], dtype=torch.long) * t\n",
    "        x_t, _ = diffusion.q_sample(x_0, t_tensor)\n",
    "        \n",
    "        ax = axes[i, j]\n",
    "        ax.scatter(x_t[:, 0].numpy(), x_t[:, 1].numpy(), alpha=0.5, s=1)\n",
    "        ax.set_xlim(-4, 4)\n",
    "        ax.set_ylim(-4, 4)\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.set_title(f't={t}')\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(schedule_name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e389ebd3",
   "metadata": {},
   "source": [
    "## 测试离散数据的扩散过程\n",
    "\n",
    "接下来我们测试离散数据的扩散过程。我们将：\n",
    "1. 创建一个简单的离散序列数据\n",
    "2. 使用不同的schedule进行扩散\n",
    "3. 观察token分布的变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bd687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置参数\n",
    "vocab_size = 10\n",
    "seq_length = 20\n",
    "batch_size = 16\n",
    "\n",
    "# 创建一些示例序列数据（每个位置都偏好某些特定的token）\n",
    "def create_biased_sequences(batch_size, seq_length, vocab_size):\n",
    "    # 创建一个偏好模式：每个位置倾向于使用特定的token\n",
    "    position_biases = torch.arange(seq_length) % (vocab_size // 2)\n",
    "    sequences = position_biases.repeat(batch_size, 1)\n",
    "    # 添加一些随机性\n",
    "    mask = torch.rand(batch_size, seq_length) > 0.7\n",
    "    random_tokens = torch.randint(0, vocab_size, (batch_size, seq_length))\n",
    "    sequences[mask] = random_tokens[mask]\n",
    "    return sequences\n",
    "\n",
    "# 创建初始序列\n",
    "x_0 = create_biased_sequences(batch_size, seq_length, vocab_size)\n",
    "\n",
    "# 使用余弦schedule进行测试（通常对离散数据效果较好）\n",
    "schedule = CosineSchedule(num_timesteps)\n",
    "discrete_diffusion = DiscreteDataDiffusion(schedule, vocab_size)\n",
    "\n",
    "# 可视化不同时间步的token分布\n",
    "fig, axes = plt.subplots(1, len(timesteps), figsize=(20, 4))\n",
    "\n",
    "for j, t in enumerate(timesteps):\n",
    "    t_tensor = torch.ones(batch_size, dtype=torch.long) * t\n",
    "    x_t, _ = discrete_diffusion.q_sample(x_0, t_tensor)\n",
    "    \n",
    "    # 计算每个位置上token的平均分布\n",
    "    avg_distribution = x_t.mean(dim=0).numpy()\n",
    "    \n",
    "    ax = axes[j]\n",
    "    im = ax.imshow(avg_distribution, aspect='auto', cmap='viridis')\n",
    "    ax.set_title(f't={t}')\n",
    "    ax.set_xlabel('Token ID')\n",
    "    ax.set_ylabel('Position')\n",
    "    plt.colorbar(im, ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 打印某个特定位置的token分布变化\n",
    "position = 0\n",
    "print(f\"\\nPosition {position} 的token分布变化:\")\n",
    "for t in timesteps:\n",
    "    t_tensor = torch.ones(batch_size, dtype=torch.long) * t\n",
    "    x_t, _ = discrete_diffusion.q_sample(x_0, t_tensor)\n",
    "    distribution = x_t[:, position].mean(dim=0)\n",
    "    print(f\"t={t}:\")\n",
    "    print(distribution.numpy().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda70a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5256da9",
   "metadata": {},
   "source": [
    "## 测试数据加载器（DataLoader）\n",
    "\n",
    "我们将测试以下几种场景：\n",
    "1. 基础静态数据集\n",
    "2. 基础可迭代数据集\n",
    "3. 多任务静态数据集\n",
    "4. 多任务可迭代数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46dc35aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from amp.trainer.dataloader import (\n",
    "    BaseDataset,\n",
    "    IterableBaseDataset,\n",
    "    BaseDataLoader,\n",
    "    MultiTaskDataset,\n",
    "    MultiTaskIterableDataset,\n",
    "    MultiTaskDataLoader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f506c8",
   "metadata": {},
   "source": [
    "### 1. 测试基础静态数据集\n",
    "\n",
    "创建一个简单的静态数据集，模拟图像分类任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ca72422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 16\n",
      "Image shape: torch.Size([16, 3, 32, 32])\n",
      "Label shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wang-work/miniconda3/envs/amp/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "class SimpleImageDataset(BaseDataset):\n",
    "    def __init__(self, num_samples=100):\n",
    "        super().__init__()\n",
    "        # 模拟图像数据 (100, 3, 32, 32)\n",
    "        self.images = torch.randn(num_samples, 3, 32, 32)\n",
    "        # 模拟标签数据 (100,)\n",
    "        self.labels = torch.randint(0, 10, (num_samples,))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'image': self.images[index],\n",
    "            'label': self.labels[index]\n",
    "        }\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "dataset = SimpleImageDataset(num_samples=100)\n",
    "dataloader = BaseDataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "# 测试数据加载\n",
    "for batch_idx, batch in enumerate(dataloader):\n",
    "    if batch_idx == 0:  # 只打印第一个batch\n",
    "        print(f\"Batch size: {batch['image'].shape[0]}\")\n",
    "        print(f\"Image shape: {batch['image'].shape}\")\n",
    "        print(f\"Label shape: {batch['label'].shape}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcc4527",
   "metadata": {},
   "source": [
    "### 2. 测试基础可迭代数据集\n",
    "\n",
    "创建一个动态生成数据的数据集，模拟流式数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eede4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 16\n",
      "Feature shape: torch.Size([16, 10])\n",
      "Target shape: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "class StreamDataset(IterableBaseDataset):\n",
    "    def __init__(self, max_samples=100):\n",
    "        super().__init__()\n",
    "        self.max_samples = max_samples\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for _ in range(self.max_samples):\n",
    "            # 动态生成数据\n",
    "            feature = torch.randn(10)  # 10维特征\n",
    "            target = torch.sum(feature) > 0  # 二分类任务\n",
    "            yield {\n",
    "                'feature': feature,\n",
    "                'target': target\n",
    "            }\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "stream_dataset = StreamDataset(max_samples=100)\n",
    "stream_loader = BaseDataLoader(\n",
    "    dataset=stream_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=0  # 流式数据集通常使用单进程\n",
    ")\n",
    "\n",
    "# 测试数据加载\n",
    "for batch_idx, batch in enumerate(stream_loader):\n",
    "    if batch_idx == 0:  # 只打印第一个batch\n",
    "        print(f\"Batch size: {batch['feature'].shape[0]}\")\n",
    "        print(f\"Feature shape: {batch['feature'].shape}\")\n",
    "        print(f\"Target shape: {batch['target'].shape}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9d09b6",
   "metadata": {},
   "source": [
    "### 3. 测试多任务静态数据集\n",
    "\n",
    "创建一个多输入多输出的数据集，模拟多任务学习场景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8cf1cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入数据:\n",
      "- Image shape: torch.Size([8, 3, 64, 64])\n",
      "- Text shape: torch.Size([8, 20])\n",
      "\n",
      "输出数据:\n",
      "- Class shape: torch.Size([8])\n",
      "- BBox shape: torch.Size([8, 4])\n",
      "- Mask shape: torch.Size([8, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# 创建模拟数据\n",
    "num_samples = 100\n",
    "\n",
    "# 输入数据\n",
    "inputs = {\n",
    "    'image': torch.randn(num_samples, 3, 64, 64),  # 图像输入\n",
    "    'text': torch.randint(0, 1000, (num_samples, 20))  # 文本输入\n",
    "}\n",
    "\n",
    "# 目标数据\n",
    "targets = {\n",
    "    'class': torch.randint(0, 10, (num_samples,)),  # 分类任务\n",
    "    'bbox': torch.randn(num_samples, 4),  # 检测任务\n",
    "    'mask': torch.randint(0, 2, (num_samples, 64, 64))  # 分割任务\n",
    "}\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "multi_dataset = MultiTaskDataset(\n",
    "    inputs=inputs,\n",
    "    targets=targets\n",
    ")\n",
    "\n",
    "multi_loader = MultiTaskDataLoader(\n",
    "    dataset=multi_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# 测试数据加载\n",
    "for batch_idx, batch in enumerate(multi_loader):\n",
    "    if batch_idx == 0:  # 只打印第一个batch\n",
    "        print(\"输入数据:\")\n",
    "        print(f\"- Image shape: {batch['input_image'].shape}\")\n",
    "        print(f\"- Text shape: {batch['input_text'].shape}\")\n",
    "        print(\"\\n输出数据:\")\n",
    "        print(f\"- Class shape: {batch['target_class'].shape}\")\n",
    "        print(f\"- BBox shape: {batch['target_bbox'].shape}\")\n",
    "        print(f\"- Mask shape: {batch['target_mask'].shape}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0965236d",
   "metadata": {},
   "source": [
    "### 4. 测试多任务可迭代数据集\n",
    "\n",
    "创建一个动态生成多任务数据的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d48fddf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/wang-work/miniconda3/envs/amp/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/wang-work/miniconda3/envs/amp/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'multi_task_generator' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 12258) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1284\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py:73\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 12258) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 30\u001b[0m\n\u001b[1;32m     23\u001b[0m stream_multi_loader \u001b[38;5;241m=\u001b[39m MultiTaskDataLoader(\n\u001b[1;32m     24\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mstream_multi_dataset,\n\u001b[1;32m     25\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m     26\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# 流式数据集使用单进程\u001b[39;00m\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 测试数据加载\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(stream_multi_loader):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# 只打印第一个batch\u001b[39;00m\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m输入数据:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1491\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data, worker_id)\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1491\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1453\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1449\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1452\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1453\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1455\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1297\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1296\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 12258) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "def multi_task_generator(worker_id):\n",
    "    # 通过 worker_id 设置种子，确保不同 worker 生成不同样本\n",
    "    torch.manual_seed(worker_id + 42)\n",
    "    \n",
    "    inputs = (\n",
    "        torch.randn(3, 32, 32),\n",
    "        torch.randint(0, 100, (10,))\n",
    "    )\n",
    "    targets = (\n",
    "        torch.randint(0, 5, (1,))[0],\n",
    "        torch.randn(2)\n",
    "    )\n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "stream_multi_dataset = MultiTaskIterableDataset(\n",
    "    data_generator=multi_task_generator,\n",
    "    input_names=['image', 'text'],\n",
    "    target_names=['class', 'regression']\n",
    ")\n",
    "\n",
    "stream_multi_loader = MultiTaskDataLoader(\n",
    "    dataset=stream_multi_dataset,\n",
    "    batch_size=4,\n",
    "    num_workers=1  # 流式数据集使用单进程\n",
    ")\n",
    "\n",
    "# 测试数据加载\n",
    "for batch_idx, batch in enumerate(stream_multi_loader):\n",
    "    if batch_idx == 0:  # 只打印第一个batch\n",
    "        print(\"输入数据:\")\n",
    "        print(f\"- Image shape: {batch['input_image'].shape}\")\n",
    "        print(f\"- Text shape: {batch['input_text'].shape}\")\n",
    "        print(\"\\n输出数据:\")\n",
    "        print(f\"- Class shape: {batch['target_class'].shape}\")\n",
    "        print(f\"- Regression shape: {batch['target_regression'].shape}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5516e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b9c267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0099bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d485d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd47f3bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04495db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403e2083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acfa3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471b3498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53980df7",
   "metadata": {},
   "source": [
    "## 测试多进程数据加载\n",
    "\n",
    "我们将测试不同worker数量对数据加载速度的影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503151a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "测试不同worker数量的加载时间:\n",
      "----------------------------------------\n",
      " Workers |   Time (s) |  Samples/s\n",
      "----------------------------------------\n",
      "       0 |       0.02 |     419531\n",
      "       0 |       0.02 |     419531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/wang-work/miniconda3/envs/amp/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/wang-work/miniconda3/envs/amp/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'SimpleImageDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 12156) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1284\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py:73\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 12156) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m40\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_workers \u001b[38;5;129;01min\u001b[39;00m worker_nums:\n\u001b[0;32m---> 36\u001b[0m     time_taken, total_samples \u001b[38;5;241m=\u001b[39m \u001b[43mtest_dataloader_speed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     samples_per_second \u001b[38;5;241m=\u001b[39m total_samples \u001b[38;5;241m/\u001b[39m time_taken\n\u001b[1;32m     38\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend((num_workers, time_taken, samples_per_second))\n",
      "Cell \u001b[0;32mIn[9], line 20\u001b[0m, in \u001b[0;36mtest_dataloader_speed\u001b[0;34m(num_workers)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 遍历整个数据集\u001b[39;00m\n\u001b[1;32m     19\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     21\u001b[0m     total_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     23\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1491\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data, worker_id)\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1491\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1453\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1449\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1452\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1453\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1455\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/amp/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1297\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1296\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 12156) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "def test_dataloader_speed(num_workers):\n",
    "    # 创建一个较大的数据集来测试\n",
    "    dataset = SimpleImageDataset(num_samples=10000)\n",
    "    \n",
    "    dataloader = BaseDataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 遍历整个数据集\n",
    "    total_samples = 0\n",
    "    for batch in dataloader:\n",
    "        total_samples += batch['image'].shape[0]\n",
    "    \n",
    "    end_time = time.time()\n",
    "    return end_time - start_time, total_samples\n",
    "\n",
    "# 测试不同的worker数量\n",
    "worker_nums = [0, 1, 2, 4, mp.cpu_count()]\n",
    "results = []\n",
    "\n",
    "print(\"\\n测试不同worker数量的加载时间:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'Workers':>8} | {'Time (s)':>10} | {'Samples/s':>10}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for num_workers in worker_nums:\n",
    "    time_taken, total_samples = test_dataloader_speed(num_workers)\n",
    "    samples_per_second = total_samples / time_taken\n",
    "    results.append((num_workers, time_taken, samples_per_second))\n",
    "    print(f\"{num_workers:8d} | {time_taken:10.2f} | {samples_per_second:10.0f}\")\n",
    "\n",
    "# 绘制结果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# 时间对比\n",
    "plt.subplot(1, 2, 1)\n",
    "workers = [r[0] for r in results]\n",
    "times = [r[1] for r in results]\n",
    "plt.plot(workers, times, 'o-')\n",
    "plt.xlabel('Number of Workers')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.title('Loading Time vs Number of Workers')\n",
    "\n",
    "# 吞吐量对比\n",
    "plt.subplot(1, 2, 2)\n",
    "speeds = [r[2] for r in results]\n",
    "plt.plot(workers, speeds, 'o-')\n",
    "plt.xlabel('Number of Workers')\n",
    "plt.ylabel('Samples per Second')\n",
    "plt.title('Throughput vs Number of Workers')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7786093e",
   "metadata": {},
   "source": [
    "### 测试多任务数据集的多进程加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f21ae03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "测试多任务数据集在不同worker数量下的加载时间:\n",
      "--------------------------------------------------\n",
      " Workers |   Time (s) |  Samples/s\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'worker_nums' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m     50\u001b[0m results_multi \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_workers \u001b[38;5;129;01min\u001b[39;00m \u001b[43mworker_nums\u001b[49m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m         time_taken, total_samples \u001b[38;5;241m=\u001b[39m test_multi_task_loader_speed(num_workers)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'worker_nums' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "def test_multi_task_loader_speed(num_workers):\n",
    "    # 创建较大的多任务数据集\n",
    "    num_samples = 100000\n",
    "    \n",
    "    # 输入数据\n",
    "    inputs = {\n",
    "        'image': torch.randn(num_samples, 3, 64, 64),\n",
    "        'text': torch.randint(0, 1000, (num_samples, 20))\n",
    "    }\n",
    "    \n",
    "    # 目标数据\n",
    "    targets = {\n",
    "        'class': torch.randint(0, 10, (num_samples,)),\n",
    "        'bbox': torch.randn(num_samples, 4),\n",
    "        'mask': torch.randint(0, 2, (num_samples, 64, 64))\n",
    "    }\n",
    "    \n",
    "    # 创建数据集和数据加载器\n",
    "    dataset = MultiTaskDataset(\n",
    "        inputs=inputs,\n",
    "        targets=targets\n",
    "    )\n",
    "    \n",
    "    loader = MultiTaskDataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=1024,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 遍历整个数据集\n",
    "    total_samples = 0\n",
    "    for batch in loader:\n",
    "        total_samples += batch['input_image'].shape[0]\n",
    "    \n",
    "    end_time = time.time()\n",
    "    return end_time - start_time, total_samples\n",
    "\n",
    "# 测试不同的worker数量\n",
    "print(\"\\n测试多任务数据集在不同worker数量下的加载时间:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Workers':>8} | {'Time (s)':>10} | {'Samples/s':>10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "results_multi = []\n",
    "for num_workers in worker_nums:\n",
    "    try:\n",
    "        time_taken, total_samples = test_multi_task_loader_speed(num_workers)\n",
    "        samples_per_second = total_samples / time_taken\n",
    "        results_multi.append((num_workers, time_taken, samples_per_second))\n",
    "        print(f\"{num_workers:8d} | {time_taken:10.2f} | {samples_per_second:10.0f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{num_workers:8d} | Failed: {str(e)}\")\n",
    "\n",
    "# 绘制结果\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# 时间对比\n",
    "plt.subplot(1, 2, 1)\n",
    "workers = [r[0] for r in results_multi]\n",
    "times = [r[1] for r in results_multi]\n",
    "plt.plot(workers, times, 'o-')\n",
    "plt.xlabel('Number of Workers')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.title('Multi-task Loading Time vs Number of Workers')\n",
    "\n",
    "# 吞吐量对比\n",
    "plt.subplot(1, 2, 2)\n",
    "speeds = [r[2] for r in results_multi]\n",
    "plt.plot(workers, speeds, 'o-')\n",
    "plt.xlabel('Number of Workers')\n",
    "plt.ylabel('Samples per Second')\n",
    "plt.title('Multi-task Throughput vs Number of Workers')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62fa196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19c2071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f3a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
